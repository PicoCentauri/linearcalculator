"""Utility functions for generating and evaluating the linear models."""
from math import sqrt
from typing import List, Union

import ase.io
import equistore
import matplotlib.pyplot as plt
import numpy as np
from equistore import Labels, TensorBlock, TensorMap
from sklearn.model_selection import train_test_split


PARAMETER_KEYS_DICT = {"e": ["values"], "e_f": ["values", "positions"]}


def setup_dataset(filenames: List[List[ase.Atoms]]):
    """
    Read and process `ase.Atoms` from files.

    Parameters:
    -----------
    filenames: list of `ase.Atoms` objects
        List of ASE Atoms objects to read from.

    Returns:
    --------
    frames: list of `ase.Atoms` objects
    """
    if type(filenames) not in [list, tuple]:
        filenames = [filenames]

    frames = []
    for filename in filenames:
        frames += ase.io.read(filename, ":")

    return frames


def training_curve_split(
    n_structures: int,
    train_size: Union[float, int],
    n_train_num: int,
    n_train_start: int = 1,
    random_state: int = None,
):
    """Set up a arrays for a training curve.

    Split the dataset a testing and multiple training sets. The returned arrays can be
    used to perform training and evaluation of machine learning models for various
    training set sizes, allowing for the creation of a training curve.

    Parameters
    ----------
    n_structures : int
        The total number of data structures or samples in the dataset.
    train_size : float or int
        The proportion or absolute number of samples to be included in the training set.
        If float, it should be between 0.0 and 1.0, representing the fraction of the
        dataset. If int, it represents the absolute number of samples.
    n_train_num : int
        The total number of training sizes to generate.
    n_train_start : int
        The starting number of training samples.
    random_state : int
        Determines the random seed for shuffling and splitting the data.

    Returns
    -------
    l_idx_train : List[numpy.ndarray]
        A list of arrays containing the indices representing the selected testing samples.
        The number of indices are generated on a geometric scale.
    idx_test : numpy.ndarray
        An array of indices representing the selected test samples.
    """

    idx_train, idx_test = train_test_split(
        range(n_structures), train_size=train_size, random_state=random_state
    )

    n_training_strutures = np.geomspace(
        start=n_train_start,
        stop=len(idx_train),
        num=n_train_num,
        endpoint=True,
        dtype=int,
    )

    return [idx_train[:i] for i in n_training_strutures], idx_test


def compute_power_spectrum(
    spherical_expansion_1: TensorMap, spherical_expansion_2: TensorMap = None
):
    """
    Compute the rotationally invariant power spectrum from spherical expansion
    coefficients.

    This function takes the spherical expansion coefficients and generates the
    rotationally invariant power spectrum. The power spectrum is obtained by combining
    coefficients from two different calculators or by taking quadratic combinations of
    the same coefficients. The resulting features are stored in a Descriptor object.

    If `spherical_expansion_2` is not provided, it is assumed that the invariants are
    generated by taking quadratic combinations of the coefficients from
    `spherical_expansion_1`. Otherwise, invariants are generated by combining
    coefficients from `spherical_expansion_1` and `spherical_expansion_2`.

    Parameters
    ----------
    spherical_expansion_1 : equistore.TensorMap
        The spherical expansion coefficients obtained from an external code,
        representing the expansion of the 1-center.
    spherical_expansion_2 : equistore.TensorMap, optional
        The spherical expansion coefficients obtained from an external code,
        representing the expansion of the 2-center. If not provided, the same spherical
        expansion coefficients as `spherical_expansion_1` are used.

    Returns
    -------
    Descriptor : TensorMap
        A Descriptor object containing the rotationally invariant features and their
        associated labels.
    """

    # Make sure that the expansion coefficients have the correct set of keys
    # associated with 1-center expansion coefficients.
    assert spherical_expansion_1.keys.names == (
        "spherical_harmonics_l",
        "species_center",
        "species_neighbor",
    )

    # If two different sets of coefficients are provided, it is assumed
    # that the invariants are generated by taking quadratic combinations
    # of those.
    # Otherwise, invariants are generated by combining coefficients from
    # two different calculators.
    if spherical_expansion_2 is None:
        use_same_spherical_expansions = True
        spherical_expansion_2 = spherical_expansion_1
    else:
        use_same_spherical_expansions = False
        assert spherical_expansion_2.keys.names == (
            "spherical_harmonics_l",
            "species_center",
            "species_neighbor",
        )

    blocks = []
    keys = []

    for (l1, cs1, ns1), spx_1 in spherical_expansion_1:
        for (l2, cs2, ns2), spx_2 in spherical_expansion_2:
            if l1 != l2 or cs1 != cs2:
                continue

            # Find common samples if samples are not the same
            if not np.all(spx_1.samples == spx_2.samples):
                common_samples = Labels(
                    names=spx_1.samples.names,
                    values=np.asarray(
                        np.intersect1d(spx_1.samples, spx_2.samples).tolist()
                    ),
                )

                if len(common_samples) == 0:
                    continue

                spx_1 = equistore.slice_block(
                    spx_1, axis="samples", labels=common_samples
                )
                spx_2 = equistore.slice_block(
                    spx_2, axis="samples", labels=common_samples
                )

            # Avoid doubly computing / storing invariants that are
            # the same by symmetry of the neighbor species.
            # Example: Neighbor species (Na, Cl) produces the same
            # invariants as (Cl, Na), meaning that only one set
            # of invariants needs to be used.
            # If the two sets of expansion coefficients are different,
            # this does not apply
            if ns1 > ns2 and use_same_spherical_expansions:
                continue
            elif ns1 == ns2:
                factor = 1.0 / sqrt(2 * l1 + 1)
            else:
                factor = sqrt(2) / sqrt(2 * l1 + 1)

            properties = Labels(
                names=[f"{name}_1" for name in spx_1.properties.names]
                + [f"{name}_2" for name in spx_2.properties.names],
                values=np.array(
                    [
                        properties_1.tolist() + properties_2.tolist()
                        for properties_1 in spx_1.properties
                        for properties_2 in spx_2.properties
                    ],
                    dtype=np.int32,
                ),
            )

            # Compute the invariants by summation and store the results
            # Operation: ima, imb -> iab
            data = factor * np.matmul(spx_1.values.swapaxes(1, 2), spx_2.values)

            block = TensorBlock(
                values=data.reshape(data.shape[0], -1),
                samples=spx_1.samples,
                components=[],
                properties=properties,
            )

            n_properties = block.values.shape[1]

            if spx_1.has_gradient("positions"):
                gradient_1 = spx_1.gradient("positions")
                gradient_2 = spx_2.gradient("positions")

                if len(gradient_1.samples) == 0 or len(gradient_2.samples) == 0:
                    continue

                gradients_samples = np.unique(
                    np.concatenate([gradient_1.samples, gradient_2.samples])
                )
                gradients_samples = gradients_samples.view(np.int32).reshape(-1, 3)

                gradients_samples = Labels(
                    names=gradient_1.samples.names, values=gradients_samples
                )

                gradients_sample_mapping = {
                    tuple(sample): i for i, sample in enumerate(gradients_samples)
                }

                gradient_data = np.zeros([gradients_samples.shape[0], 3, n_properties])

                # operation: ixma, imb -> ixab
                gradient_data_1 = factor * np.matmul(
                    gradient_1.data.swapaxes(2, 3),
                    spx_2.values[gradient_1.samples["sample"], np.newaxis, :, :],
                ).reshape(gradient_1.samples.shape[0], 3, -1)

                for sample, row in zip(gradient_1.samples, gradient_data_1):
                    new_row = gradients_sample_mapping[tuple(sample)]
                    gradient_data[new_row, :, :] += row

                # operation: ima, ixmb -> ixab
                gradient_data_2 = factor * np.matmul(
                    spx_1.values[
                        gradient_2.samples["sample"], np.newaxis, :, :
                    ].swapaxes(2, 3),
                    gradient_2.data,
                ).reshape(gradient_2.samples.shape[0], 3, -1)

                for sample, row in zip(gradient_2.samples, gradient_data_2):
                    new_row = gradients_sample_mapping[tuple(sample)]
                    gradient_data[new_row, :, :] += row

                assert gradient_1.components[0].names == ("direction",)
                block.add_gradient(
                    "positions",
                    gradient_data,
                    gradients_samples,
                    [gradient_1.components[0]],
                )

            keys.append((l1, cs1, ns1, ns2))
            blocks.append(block)

    keys = Labels(
        names=[
            "spherical_harmonics_l",
            "species_center",
            "species_neighbor_1",
            "species_neighbor_2",
        ],
        values=np.array(keys, dtype=np.int32),
    )
    descriptor = TensorMap(keys, blocks)
    descriptor.keys_to_properties("spherical_harmonics_l")

    return descriptor


def plot_realization(realization: dict, fname: str = None):
    """Plot the realization using the provided data and save the figure.

    This function creates a figure with two subplots. The first subplot displays the energy-related
    data, including train and test root mean squared error (RMSE) values, along with scatter points
    representing the optimal α values for train and test RMSE.

    The second subplot displays the force-related
    data, including train and test RMSE values for different α values, along with scatter points for the
    optimal α values. The figure is saved if the `fname` parameter is provided.

    Parameters
    ----------
    realization : dict
        The dictionary containing the data for the realization.
    fname : str or None
        The filename (including the path) to save the figure.
        If None, the figure will not be saved.
    """

    tab10 = plt.rcParams["axes.prop_cycle"].by_key()["color"]

    fig, ax = plt.subplots(
        ncols=2,
        figsize=(12, 4),
        constrained_layout=True,
        sharey=True,
        sharex=True,
    )

    for i, key in enumerate(PARAMETER_KEYS_DICT.keys()):
        b = realization[key]
        color = tab10[i]

        # Energy subplot
        ax[0].plot(
            b.alpha_values,
            b.l_rmse_y_train,
            label=f"{key}: train, rmse_y_min = {b.rmse_y_train:.1e}",
            c=color,
            ls=":",
        )

        ax[0].plot(
            b.alpha_values,
            b.l_rmse_y_test,
            label=f"{key}: test, rmse_y_min = {b.rmse_y_test:.1e}",
            c=color,
        )

        ax[0].scatter(
            2 * [b.alpha],
            [b.rmse_y_train, b.rmse_y_test],
            c=color,
        )

        l_rmse_f_train = b.l_rmse_f_train
        l_rmse_f_test = b.l_rmse_f_test
        rmse_f_train = b.rmse_f_train
        rmse_f_test = b.rmse_f_test

        ax[1].plot(
            b.alpha_values,
            l_rmse_f_train,
            label=f"{key}: train, RMSE_f_min = {b.rmse_f_train:.1e}",
            c=color,
            ls=":",
        )

        ax[1].plot(
            b.alpha_values,
            l_rmse_f_test,
            label=f"{key}: test, RMSE_f_min = {b.rmse_f_test:.1e}",
            c=color,
        )

        ax[1].scatter(
            2 * [b.alpha],
            [rmse_f_train, rmse_f_test],
            c=color,
            label=f"α_opt={b.alpha:.1e}",
        )

    for a in ax:
        a.axhline(1e2, c="gray", ls="dashed", zorder=-5)
        a.legend()
        a.set(xscale="log", yscale="log", xlabel="α")

    ax[0].set_ylabel(r"% $RMSE_\mathrm{energy}$")
    ax[1].set_ylabel(r"% $RMSE_\mathrm{force}$")

    if fname is not None:
        fig.savefig(fname, bbox_inches="tight")
